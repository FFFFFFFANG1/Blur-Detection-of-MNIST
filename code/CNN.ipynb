{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_array = np.load('train_array.npy')\n",
    "test_array = np.load('test_array.npy')\n",
    "val_array = np.load('val_array.npy')\n",
    "train_labels = np.load('train_labels.npy')\n",
    "val_labels = np.load('val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31 136 101\n",
      "  63 189 254 255 254 254 160  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  21 154 217 253 253 253 253 253 253 253 253 253 152\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 253 253\n",
      " 253 253 233 249 253 253 253 253 253 221  37   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   2 163 163  65  65  41  59  65  65  87 234\n",
      " 253 253 135   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  22   0   0   0   0   0   0   0   0 128 253 253 135   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  20 213 253 253  86   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  48 253 253 251  17   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  59 253 253 152   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   5 180 253 253 133   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 113 253 253 234  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  82 229 253 253 134   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  87 250 253 253 154   9   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  87 251 253 253 157   7\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  31 221 250 253 253 104   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  13  30  97 148 172 253 253 240 103   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7  48  81 166\n",
      " 202 253 253 253 253 253 253 214  48   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0 129 193 253 253 253 253 253 253 253 253 253 253 253\n",
      " 250 183  95   0   0   0   0   0   0   0   0   0   0   0   0 254 253 253\n",
      " 253 253 253 253 253 253 253 253 253 253 253 253 221  84  84  51   0   0\n",
      "   0   0   0   0   0   0   0 207 253 253 253 218 152  95  35  35  35  35\n",
      "  79 197 253 253 253 253 134  21   0   0   0   0   0   0   0   0   0  18\n",
      " 135 135  47  11   0   0   0   0   0   0   0   8  23 204 253 253  53   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(val_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.0178 - accuracy: 0.9912\n",
      "Epoch 2/5\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 8.8128e-06 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 2.2779e-06 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 1.0846e-06 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 1.2873e-06 - accuracy: 1.0000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 4.2824e-07 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == -1: train_labels[i] = 0\n",
    "for i in range(len(val_labels)):\n",
    "    if val_labels[i] == -1: val_labels[i] = 0\n",
    "\n",
    "\n",
    "# normalization\n",
    "train_array = train_array / 255.0\n",
    "val_array = val_array / 255.0\n",
    "test_array = test_array / 255.0\n",
    "\n",
    "# reshape\n",
    "train_array = train_array.reshape((train_array.shape[0], 28, 28, 1))\n",
    "val_array = val_array.reshape((val_array.shape[0], 28, 28, 1))\n",
    "test_array = test_array.reshape((test_array.shape[0], 28, 28, 1))\n",
    "\n",
    "# CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    # layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "              metrics = 'accuracy')\n",
    "\n",
    "model.fit(train_array, train_labels, epochs = 5, batch_size = 50)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(val_array, val_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "[[1.2704610e-03]\n",
      " [1.0269368e-03]\n",
      " [9.9999982e-01]\n",
      " [9.9999958e-01]\n",
      " [7.9022668e-04]\n",
      " [7.7354710e-04]\n",
      " [9.9999881e-01]\n",
      " [9.9997866e-01]\n",
      " [1.0303344e-03]\n",
      " [9.7857241e-04]\n",
      " [2.3379782e-03]\n",
      " [9.9999845e-01]\n",
      " [7.7354710e-04]\n",
      " [9.9997407e-01]\n",
      " [1.4511710e-03]\n",
      " [7.7354710e-04]\n",
      " [7.7354710e-04]\n",
      " [8.0430479e-04]\n",
      " [7.7354710e-04]\n",
      " [8.3836872e-04]\n",
      " [7.7391573e-04]\n",
      " [9.9999827e-01]\n",
      " [9.9997681e-01]\n",
      " [8.1715506e-04]\n",
      " [9.9998248e-01]\n",
      " [7.7354710e-04]\n",
      " [9.9998820e-01]\n",
      " [9.9990195e-01]\n",
      " [9.9999619e-01]\n",
      " [9.9909788e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[:30])\n",
    "print(model.predict(train_array[:30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_array)  \n",
    "\n",
    "output = []\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] > 0.5: output.append(1)\n",
    "    else: output.append(-1)\n",
    "\n",
    "input_file = 'cig_interview_data/test.txt'\n",
    "output_file = 'cig_interview_data/test_CNN.txt'\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "assert len(lines) == len(y_pred)\n",
    "\n",
    "modified_lines = [line.rstrip('0\\n') + str(output[i]) + '\\n' for i, line in enumerate(lines)]\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.writelines(modified_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
